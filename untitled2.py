# -*- coding: utf-8 -*-
"""Untitled2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfxLU39AzpKKKZuMm4JE6KKPBc67Xos_
"""

import os
import zipfile
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2, VGG16, ResNet50
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from google.colab import files
import shutil
from pathlib import Path
import random
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns

print("Libraries imported successfully")
print(f"version TensorFlow: {tf.__version__}")

def create_teeth_dataset_structure():

    folders = [
        "/content/dataset/train/healthy/",
        "/content/dataset/train/caries/",
        "/content/dataset/train/severe/",
        "/content/dataset/validation/healthy/",
        "/content/dataset/validation/caries/",
        "/content/dataset/validation/severe/"
    ]

    for folder in folders:
        os.makedirs(folder, exist_ok=True)
        print(f"ØªÙ… Ø¥Ù†Ø´Ø§Ø¡: {folder}")

    print("\n folder structure is ready")
    return "/content/dataset/"

dataset_path = create_teeth_dataset_structure()

def upload_and_extract_archive():

    print("upload a file archive.zip...")
    uploaded = files.upload()

    if not uploaded:
        print("No file has been uploaded")
        return None

    zip_filename = list(uploaded.keys())[0]

    zip_path = f"/content/{zip_filename}"
    with open(zip_path, 'wb') as f:
        f.write(uploaded[zip_filename])

    print(f"The file has been uploaded: {zip_filename}")

    extract_path = "/content/extracted_images/"
    os.makedirs(extract_path, exist_ok=True)

    print("The file is being decompressed")
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)

    print(f"Decompressed to: {extract_path}")

    os.remove(zip_path)

    return extract_path

extracted_path = upload_and_extract_archive()

def organize_images_flexible_fixed():

    global extracted_path

    if not extracted_path:
        print("There is no path to the extracted images")
        return

    all_images = []
    for root, dirs, files in os.walk(extracted_path):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                all_images.append(os.path.join(root, file))

    total_images = len(all_images)
    print(f"\n ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ {total_images} ØµÙˆØ±Ø©")

    while True:
        try:
            num_to_classify = int(input(f"\nÙƒÙ… ØµÙˆØ±Ø© ØªØ±ÙŠØ¯ ØªØµÙ†ÙŠÙÙ‡Ø§ØŸ (Ø­Ø¯ Ø£Ù‚ØµÙ‰ {total_images}): "))
            if 1 <= num_to_classify <= total_images:
                break
            else:
                print(f" Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø¨ÙŠÙ† 1 Ùˆ {total_images}")
        except ValueError:
            print(" Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… ØµØ­ÙŠØ­")

    selected_images = random.sample(all_images, num_to_classify)

    print(f"\n Ø³ÙŠØªÙ… ØªØµÙ†ÙŠÙ {num_to_classify} ØµÙˆØ±Ø©")
    print("=" * 60)

    stats = {cat: {'train': 0, 'val': 0} for cat in ['healthy', 'caries', 'severe']}

    categories = {
        '1': ('healthy', 'Ø³Ù„ÙŠÙ…'),
        '2': ('caries', 'ØªØ³ÙˆØ³ Ø¨Ø³ÙŠØ·'),
        '3': ('severe', 'ØªØ³ÙˆØ³ Ø´Ø¯ÙŠØ¯')
    }

    train_ratio = 0.7
    for i, img_path in enumerate(selected_images, 1):
        print(f"\n{'='*60}")
        print(f"  Ø§Ù„ØµÙˆØ±Ø© Ø±Ù‚Ù… {i} Ù…Ù† {num_to_classify}")
        print("Ø³ÙŠØªÙ… Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ Ø§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Enter...")

        input("Ø§Ø¶ØºØ· Enter Ù„Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© >>> ")

        try:
            plt.figure(figsize=(8, 6))
            img = plt.imread(img_path)
            plt.imshow(img)
            plt.title(f"ØµÙˆØ±Ø© Ø£Ø³Ù†Ø§Ù† Ø±Ù‚Ù… {i}", fontsize=14)
            plt.axis('off')
            plt.show()
        except Exception as e:
            print(f" Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©: {e}")

        print("\n" + "="*60)
        print(" ØªØµÙ†ÙŠÙ Ø§Ù„ØµÙˆØ±Ø©:")
        print("-" * 30)
        print("1. ğŸŸ¢ Ø³Ù„ÙŠÙ… (healthy)")
        print("2. ğŸŸ¡ ØªØ³ÙˆØ³ Ø¨Ø³ÙŠØ· (caries)")
        print("3. ğŸ”´ ØªØ³ÙˆØ³ Ø´Ø¯ÙŠØ¯ (severe)")
        print("4. â­ï¸  ØªØ®Ø·ÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©")
        print("5. ğŸ›‘ Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ù…Ø¨ÙƒØ±Ø§Ù‹")
        print("-" * 30)

        while True:
            try:
                choice = input("Ø§Ø®ØªØ± Ø±Ù‚Ù…Ø§Ù‹ (1-5): ").strip()

                if choice == '5':
                    print("ğŸ›‘ ØªÙ… Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØµÙ†ÙŠÙ Ù…Ø¨ÙƒØ±Ø§Ù‹")
                    print_final_results(stats)
                    return

                elif choice == '4':
                    print("ØªÙ… ØªØ®Ø·ÙŠ Ø§Ù„ØµÙˆØ±Ø©")
                    break

                elif choice in ['1', '2', '3']:
                    category, ar_name = categories[choice]

                    total_classified = sum(stats[cat]['train'] + stats[cat]['val'] for cat in stats)
                    if total_classified < num_to_classify * train_ratio:
                        stats[category]['train'] += 1
                        dest_folder = f"/content/dataset/train/{category}/"
                        set_type = "ØªØ¯Ø±ÙŠØ¨"
                    else:
                        stats[category]['val'] += 1
                        dest_folder = f"/content/dataset/validation/{category}/"
                        set_type = "ØªØ­Ù‚Ù‚"

                    cat_total = stats[category]['train'] + stats[category]['val']
                    filename = f"tooth_{category}_{cat_total}{Path(img_path).suffix}"
                    dest_path = os.path.join(dest_folder, filename)
                    shutil.copy2(img_path, dest_path)

                    print(f"ØªÙ… Ø§Ù„Ø­ÙØ¸: {set_type} - {ar_name}")

                    print(f"\n ØªÙ‚Ø¯Ù…: {i}/{num_to_classify}")
                    print(f"   ØªØ¯Ø±ÙŠØ¨: {sum(stats[cat]['train'] for cat in stats)}")
                    print(f"   ØªØ­Ù‚Ù‚: {sum(stats[cat]['val'] for cat in stats)}")
                    break
                else:
                    print(" Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø±Ù‚Ù… Ø¨ÙŠÙ† 1 Ùˆ 5")
            except Exception as e:
                print(f" Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„: {e}")

    print_final_results(stats)

def print_final_results(stats):
    """
    Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø© Ù„Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
    """
    print("\n" + "="*60)
    print(" Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©:")
    print("="*60)

    total_train = sum(stats[cat]['train'] for cat in stats)
    total_val = sum(stats[cat]['val'] for cat in stats)

    for cat, ar in [('healthy', 'Ø³Ù„ÙŠÙ…'), ('caries', 'ØªØ³ÙˆØ³ Ø¨Ø³ÙŠØ·'), ('severe', 'ØªØ³ÙˆØ³ Ø´Ø¯ÙŠØ¯')]:
        train = stats[cat]['train']
        val = stats[cat]['val']
        total = train + val
        if total > 0:
            print(f"\n{ar}:")
            print(f"    ØªØ¯Ø±ÙŠØ¨: {train}")
            print(f"    ØªØ­Ù‚Ù‚: {val}")
            print(f"    Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {total}")

    print(f"\n Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ:")
    print(f"   Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {total_train}")
    print(f"   Ø§Ù„ØªØ­Ù‚Ù‚: {total_val}")
    print(f"   Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {total_train + total_val}")

    report = f"""
Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØµÙ†ÙØ©: {total_train + total_val}
Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {total_train}
Ø§Ù„ØªØ­Ù‚Ù‚: {total_val}

- Ø³Ù„ÙŠÙ…: ØªØ¯Ø±ÙŠØ¨={stats['healthy']['train']}, ØªØ­Ù‚Ù‚={stats['healthy']['val']}
- ØªØ³ÙˆØ³ Ø¨Ø³ÙŠØ·: ØªØ¯Ø±ÙŠØ¨={stats['caries']['train']}, ØªØ­Ù‚Ù‚={stats['caries']['val']}
- ØªØ³ÙˆØ³ Ø´Ø¯ÙŠØ¯: ØªØ¯Ø±ÙŠØ¨={stats['severe']['train']}, ØªØ­Ù‚Ù‚={stats['severe']['val']}

    with open("/content/classification_report.txt", 'w') as f:
        f.write(report)
    print("\n ØªÙ… Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ: /content/classification_report.txt")

organize_images_flexible_fixed()

def prepare_data_generators():

    train_path = "/content/dataset/train/"
    val_path = "/content/dataset/validation/"

    train_datagen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest'
    )

    val_datagen = ImageDataGenerator(rescale=1./255)


    batch_size = 8

    train_generator = train_datagen.flow_from_directory(
        train_path,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        classes=['healthy', 'caries', 'severe'],
        shuffle=True
    )

    validation_generator = val_datagen.flow_from_directory(
        val_path,
        target_size=(224, 224),
        batch_size=batch_size,
        class_mode='categorical',
        classes=['healthy', 'caries', 'severe'],
        shuffle=False
    )

    print(f"\n ÙØ¦Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_generator.class_indices}")
    print(f"Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {train_generator.samples}")
    print(f"Ø¹Ø¯Ø¯ ØµÙˆØ± Ø§Ù„ØªØ­Ù‚Ù‚: {validation_generator.samples}")

    return train_generator, validation_generator

train_generator, validation_generator = prepare_data_generators()

def create_mobilenet_model():

    base_model = MobileNetV2(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    print(" ØªÙ… ØªØ­Ù…ÙŠÙ„ MobileNetV2 Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø³Ø¨Ù‚Ø§Ù‹")

    base_model.trainable = False

    model = models.Sequential([
        base_model,
        layers.GlobalAveragePooling2D(),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(3, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    print(model.summary())

    return model, base_model

def create_vgg16_model():

    base_model = VGG16(
        weights='imagenet',
        include_top=False,
        input_shape=(224, 224, 3)
    )

    base_model.trainable = False

    model = models.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(3, activation='softmax')
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    return model, base_model

model, base_model = create_mobilenet_model()

def train_model(model, base_model, train_generator, validation_generator):

    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=5,
            restore_best_weights=True,
            verbose=1
        ),
        ModelCheckpoint(
            '/content/best_teeth_model.h5',
            monitor='val_accuracy',
            save_best_only=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,
            patience=3,
            min_lr=1e-7,
            verbose=1
        )
    ]

    print("\nğŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 1: ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø¶Ø§ÙØ©...")
    history1 = model.fit(
        train_generator,
        epochs=20,
        validation_data=validation_generator,
        callbacks=callbacks,
        verbose=1
    )

    print("\nğŸ”„ Ø§Ù„Ù…Ø±Ø­Ù„Ø© 2: Fine-tuning Ù„Ù„Ù†Ù…ÙˆØ°Ø¬...")

    base_model.trainable = True
    for layer in base_model.layers[:100]:
        layer.trainable = False

    model.compile(
        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),
        loss='categorical_crossentropy',
        metrics=['accuracy']
    )

    history2 = model.fit(
        train_generator,
        epochs=10,
        validation_data=validation_generator,
        callbacks=callbacks,
        verbose=1
    )

    history = {}
    for key in history1.history.keys():
        history[key] = history1.history[key] + history2.history[key]

    return history

history = train_model(model, base_model, train_generator, validation_generator)

def evaluate_model(model, train_generator, validation_generator, history):
    fig, axes = plt.subplots(1, 2, figsize=(15, 5))

    axes[0].plot(history['accuracy'], label='Train Accuracy')
    axes[0].plot(history['val_accuracy'], label='Validation Accuracy')
    axes[0].set_title('Model Accuracy')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('Accuracy')
    axes[0].legend()
    axes[0].grid(True)

    axes[1].plot(history['loss'], label='Train Loss')
    axes[1].plot(history['val_loss'], label='Validation Loss')
    axes[1].set_title('Model Loss')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Loss')
    axes[1].legend()
    axes[1].grid(True)

    plt.tight_layout()
    plt.show()

    print("\nğŸ“Š Ø§Ù„ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ:")
    val_loss, val_accuracy = model.evaluate(validation_generator)
    print(f"Ø¯Ù‚Ø© Ø§Ù„ØªØ­Ù‚Ù‚: {val_accuracy:.2%}")
    print(f"Ø®Ø³Ø§Ø±Ø© Ø§Ù„ØªØ­Ù‚Ù‚: {val_loss:.4f}")

    validation_generator.reset()
    predictions = model.predict(validation_generator)
    predicted_classes = np.argmax(predictions, axis=1)
    true_classes = validation_generator.classes
    class_labels = list(validation_generator.class_indices.keys())

    cm = confusion_matrix(true_classes, predicted_classes)
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_labels,
                yticklabels=class_labels)
    plt.title('Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.show()

    print("\nğŸ“‹ ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØµÙ†ÙŠÙ:")
    print(classification_report(true_classes, predicted_classes,
                               target_names=class_labels))

evaluate_model(model, train_generator, validation_generator, history)

def predict_teeth_image(model, img_path):

    from tensorflow.keras.preprocessing import image

    img = image.load_img(img_path, target_size=(224, 224))
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = img_array / 255.0  # ØªØ·Ø¨ÙŠØ¹

    predictions = model.predict(img_array)
    predicted_class = np.argmax(predictions[0])
    confidence = np.max(predictions[0])

    classes = ['Ø³Ù„ÙŠÙ… (Healthy)', 'ØªØ³ÙˆØ³ Ø¨Ø³ÙŠØ· (Caries)', 'ØªØ³ÙˆØ³ Ø´Ø¯ÙŠØ¯ (Severe)']

    plt.figure(figsize=(6, 6))
    plt.imshow(img)
    plt.title(f"Ø§Ù„Ù†ØªÙŠØ¬Ø©: {classes[predicted_class]}\nØ§Ù„Ø«Ù‚Ø©: {confidence:.2%}")
    plt.axis('off')
    plt.show()

    print("\nğŸ“Š Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª ÙƒÙ„ ÙØ¦Ø©:")
    for i, class_name in enumerate(classes):
        print(f"{class_name}: {predictions[0][i]:.2%}")

    return predicted_class, confidence

def test_multiple_images(model):

    print("ğŸ“¤ Ø§Ø±ÙØ¹ ØµÙˆØ±Ø§Ù‹ Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù†Ù…ÙˆØ°Ø¬:")
    uploaded = files.upload()

    for filename in uploaded.keys():
        print(f"\nğŸ” Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØµÙˆØ±Ø©: {filename}")
        temp_path = f"/content/{filename}"
        with open(temp_path, 'wb') as f:
            f.write(uploaded[filename])

        predict_teeth_image(model, temp_path)

        os.remove(temp_path)

def save_and_download_model(model):

    model.save('/content/teeth_caries_detector_final.h5')
    print("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: /content/teeth_caries_detector_final.h5")

    converter = tf.lite.TFLiteConverter.from_keras_model(model)
    tflite_model = converter.convert()

    with open('/content/teeth_caries_detector.tflite', 'wb') as f:
        f.write(tflite_model)
    print("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¥Ù„Ù‰ TFLite")

    files.download('/content/teeth_caries_detector_final.h5')
    print("ğŸ“¥ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")